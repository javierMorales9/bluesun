AWSTemplateFormatVersion: '2010-09-09'
Description: Stack that deploys the s3 bucket where we will upload the
             sources files and the lambda function that will trigger the
             batch job.
Parameters:
  JobQueueArn:
    Type: String
    Description: The ARN of the AWS Batch job queue
  AfterUploadJobDefinitionArn:
    Type: String
    Description: The ARN of the AWS after upload Batch job definition
  S3BucketName:
    Type: String
    Description: The name of the S3 bucket
    Default: 'sources-file-bucket'
Resources:
  S3Bucket:
    Type: AWS::S3::Bucket
    DependsOn: [AfterUploadLambdaFunction, ExampleInvokePermission]
    Properties:
      BucketName: !Ref S3BucketName
      AccessControl: Private
      CorsConfiguration:
        CorsRules:
          - AllowedHeaders:
              - "*"
            AllowedMethods:
              - PUT
              - POST
              - DELETE
              - GET
              - HEAD
            AllowedOrigins:
              - "*"
            ExposedHeaders:
              - "ETag"
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectCreated:*
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: original.mp4
            Function: !GetAtt AfterUploadLambdaFunction.Arn

  CloudfrontOriginAccessControl:
    Type: AWS::CloudFront::OriginAccessControl
    Properties:
      OriginAccessControlConfig:
        Description: "origin access control(OAC) for allowing cloudfront to access S3 bucket"
        Name: static-hosting-OAC
        OriginAccessControlOriginType: s3
        SigningBehavior: always
        SigningProtocol: sigv4

  CloudFrontDistribution:
    Type: AWS::CloudFront::Distribution
    DependsOn:
      - S3Bucket
    Properties:
      DistributionConfig:
        Origins:
          - DomainName: !Sub "${S3BucketName}.s3.eu-west-1.amazonaws.com"
            Id: static-hosting
            S3OriginConfig:
              OriginAccessIdentity: ""
            OriginAccessControlId: !GetAtt CloudfrontOriginAccessControl.Id
        Enabled: "true"
        DefaultRootObject: index.html
        CustomErrorResponses:
          - ErrorCode: 404
            ResponseCode: 200
            ResponsePagePath: /index.html
          - ErrorCode: 403
            ResponseCode: 200
            ResponsePagePath: /index.html
        HttpVersion: http2
        DefaultCacheBehavior:
          AllowedMethods:
            - DELETE
            - GET
            - HEAD
            - OPTIONS
            - PATCH
            - POST
            - PUT
          Compress: true
          TargetOriginId: static-hosting
          ForwardedValues:
            QueryString: "false"
            Cookies:
              Forward: none
          ViewerProtocolPolicy: redirect-to-https

  BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Sub "${S3BucketName}"
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: "cloudfront.amazonaws.com"
            Action: "s3:GetObject"
            Resource: !Sub "arn:aws:s3:::${S3BucketName}/*"
            Condition:
              StringEquals:
                AWS:SourceArn: !Sub "arn:aws:cloudfront::909166668781:distribution/${CloudFrontDistribution}"

  ExampleInvokePermission:
    Type: AWS::Lambda::Permission
    DependsOn: [AfterUploadLambdaFunction]
    Properties:
      FunctionName: !GetAtt AfterUploadLambdaFunction.Arn
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref AWS::AccountId
      # We create the arn manually to avoid circular dependencies. See
      # https://repost.aws/knowledge-center/unable-validate-circular-dependency-cloudformation
      SourceArn: !Sub "arn:aws:s3:::${S3BucketName}"

  ProcessingLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: allowLogging
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - logs:*
              Resource: arn:aws:logs:*:*:*
        - PolicyName: getAndDeleteObjects
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
                - s3:GetObject
                - s3:DeleteObject
              Resource: '*'
        - PolicyName: allowBatch
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
                - "batch:*"
                - "cloudwatch:GetMetricStatistics"
                - "ec2:DescribeSubnets"
                - "ec2:DescribeSecurityGroups"
                - "ec2:DescribeKeyPairs"
                - "ec2:DescribeVpcs"
                - "ec2:DescribeImages"
                - "ec2:DescribeLaunchTemplates"
                - "ec2:DescribeLaunchTemplateVersions"
                - "ecs:DescribeClusters"
                - "ecs:Describe*"
                - "ecs:List*"
                - "eks:DescribeCluster"
                - "eks:ListClusters"
                - "logs:Describe*"
                - "logs:Get*"
                - "logs:TestMetricFilter"
                - "logs:FilterLogEvents"
                - "iam:ListInstanceProfiles"
                - "iam:ListRoles"
              Resource: '*'
  AfterUploadLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: >
          const { BatchClient, SubmitJobCommand } = require("@aws-sdk/client-batch");

          async function handler(event, context, callback) {
            const client = new BatchClient();
            const command = new SubmitJobCommand({
              jobDefinition: process.env.JOB_DEFINITION,
              jobName: process.env.JOB_NAME,
              jobQueue: process.env.JOB_QUEUE,
              containerOverrides: {
                environment: [
                  {
                    name: 'INPUT_BUCKET',
                    value: event.Records[0].s3.bucket.name
                  },
                  {
                    name: 'INPUT_KEY',
                    value: decodeURI(event.Records[0].s3.object.key)
                  },
                  {
                    name: 'SOURCE_ID',
                    value: decodeURI(event.Records[0].s3.object.key).split('/')[0]
                  }
                ]
              }
            });
            try {
              const response = await client.send(command);
              console.log(response);
              return callback();
            }
            catch(err) {
              console.log(err, err.stack);
              return callback(err);
            }
            
           }

           module.exports.handler = handler;
      Handler: index.handler
      Role: !GetAtt ProcessingLambdaExecutionRole.Arn
      Runtime: nodejs18.x
      MemorySize: 512
      Timeout: 120
      Environment:
        Variables:
          JOB_QUEUE: !Ref JobQueueArn
          JOB_DEFINITION: !Ref AfterUploadJobDefinitionArn
          JOB_NAME: !Sub "after_upload_new_${AWS::StackName}"
Outputs:
  S3BucketName:
    Description: The name of the S3 bucket
    Value: !Ref S3Bucket
