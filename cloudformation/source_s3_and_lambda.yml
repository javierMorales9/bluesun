AWSTemplateFormatVersion: '2010-09-09'
Description: Stack that deploys the s3 bucket where we will upload the
             sources files and the lambda function that will trigger the
             batch job.
Parameters:
  JobQueueArn:
    Type: String
    Description: The ARN of the AWS Batch job queue
  JobDefinitionArn:
    Type: String
    Description: The ARN of the AWS Batch job definition
Resources:
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: 'sources-file-bucket'
      AccessControl: Private
      CorsConfiguration:
        CorsRules:
          - AllowedHeaders:
              - "*"
            AllowedMethods:
              - PUT
              - POST
              - DELETE
              - GET
              - HEAD
            AllowedOrigins:
              - "*"
            ExposedHeaders:
              - "ETag"
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectCreated:Put
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: txt
            Function: !GetAtt [ ProcessingLambdaFunction, Arn]

  ExampleInvokePermission:
    Type: AWS::Lambda::Permission
    DependsOn: ProcessingLambdaFunction
    Properties:
      FunctionName:
        Fn::GetAtt:
          - ProcessingLambdaFunction
          - Arn
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceArn: arn:aws:s3:::sources-file-bucket
  ProcessingLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: allowLogging
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - logs:*
              Resource: arn:aws:logs:*:*:*
        - PolicyName: getAndDeleteObjects
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
                - s3:GetObject
                - s3:DeleteObject
              Resource: '*'
        - PolicyName: allowBatch
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
                - "batch:*"
                - "cloudwatch:GetMetricStatistics"
                - "ec2:DescribeSubnets"
                - "ec2:DescribeSecurityGroups"
                - "ec2:DescribeKeyPairs"
                - "ec2:DescribeVpcs"
                - "ec2:DescribeImages"
                - "ec2:DescribeLaunchTemplates"
                - "ec2:DescribeLaunchTemplateVersions"
                - "ecs:DescribeClusters"
                - "ecs:Describe*"
                - "ecs:List*"
                - "eks:DescribeCluster"
                - "eks:ListClusters"
                - "logs:Describe*"
                - "logs:Get*"
                - "logs:TestMetricFilter"
                - "logs:FilterLogEvents"
                - "iam:ListInstanceProfiles"
                - "iam:ListRoles"
              Resource: '*'
  ProcessingLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: >
          import { BatchClient, SubmitJobCommand } from "@aws-sdk/client-batch"; // ES Modules import

          export async function handler(event, context, callback) {
            const client = new BatchClient();
            const command = new SubmitJobCommand({
              jobDefinition: process.env.JOB_DEFINITION,
              jobName: process.env.JOB_NAME,
              jobQueue: process.env.JOB_QUEUE,
              containerOverrides: {
                environment: [
                  {
                    name: 'INPUT_BUCKET',
                    value: event.Records[0].s3.bucket.name
                  },
                  {
                    name: 'INPUT_KEY',
                    value: event.Records[0].s3.object.key
                  }
                ]
              }
            });
            try {
              const response = await client.send(command);
              console.log(response);
              return callback();
            }
            catch(err) {
              console.log(err, err.stack);
              return callback(err);
            }
            
           }
      Handler: index.handler
      Role: !GetAtt ProcessingLambdaExecutionRole.Arn
      Runtime: nodejs18.x
      MemorySize: 512
      Timeout: 120
      Environment:
        Variables:
          JOB_QUEUE: !Ref JobQueueArn
          JOB_DEFINITION: !Ref JobDefinitionArn
          JOB_NAME: !Sub "after_upload_${AWS::StackName}"
